{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broke-worth",
   "metadata": {},
   "source": [
    "# MNIST classification using persistent homology and vectorizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-margin",
   "metadata": {},
   "source": [
    "In this notebook, we apply TDA to the MNIST dataset consisting of handwritten digits for classification. This notebook borrows heavily from the `giotto-tda` tutorial notebook [Classifying handwritten digits](https://giotto-ai.github.io/gtda-docs/0.4.0/notebooks/MNIST_classification.html), except for some slight modifications in the beginning and the end. I strongly encourage you to check out all that `giottto-tda` has to offer, and especially read the [giotto-tda documentation](https://giotto-ai.github.io/gtda-docs/0.4.0/index.html).\n",
    "\n",
    "The MNIST dataset consists of 70,000 handwritten digits, stored as grey scale images of 28 x 28 pixels. We will build a classifier to predict which digit is written from the image. See [The MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/) by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges for more details. \n",
    "\n",
    "For a more in-depth version of the basic pipeline outlined here, see [A Topological \"Reading\" Lesson: Classification of MNIST using TDA](https://arxiv.org/abs/1910.08345) by Ad√©lie Garin and Guillaume Tauzin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-retailer",
   "metadata": {},
   "source": [
    "### Load the dataset, binarize, split into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-celebration",
   "metadata": {},
   "source": [
    "We load the data set using `sklearn` and cast the targets as integers (instead of strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-xerox",
   "metadata": {},
   "source": [
    "So we do indeed have 70,000 images, each of which has 784 = 28 * 28 pixels. Let's check out a digit to make sure things work the way we think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = X[4].reshape(28,28)\n",
    "\n",
    "plt.imshow(digit, cmap = 'binary')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-surfing",
   "metadata": {},
   "source": [
    "That looks like a 9. Is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-implement",
   "metadata": {},
   "source": [
    "We need to pick a threshold for the Binarizer, so if the pixel value is greater than threshold, the pixel is on. Otherwise it is off. We choose 0.4, the same threshold as the [Garin et al] paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=1)\n",
    "digit_bin = binarizer.fit_transform(digit)\n",
    "\n",
    "plt.imshow(digit_bin, cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.savefig('thresh1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-advertising",
   "metadata": {},
   "source": [
    "Finally, we're ready to split the data into a training set and a test set. The `train_size` and `test_size` parameters below can be increased to make a better model at the cost of computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size, test_size = 600, 100\n",
    "\n",
    "# Reshape to (n_samples, n_pixels_x, n_pixels_y)\n",
    "X = X.reshape((-1, 28, 28))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-manual",
   "metadata": {},
   "source": [
    "### Pipeline with a single digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-harvest",
   "metadata": {},
   "source": [
    "The following pipeline can be a bit much if you're new to data science and TDA, so lets step through the entire pipeline using our binarized digit `digit`. We will think of the digit as a _cubical complex_ $C$ and build a filtration of the digit using various filtrations discussed earlier. \n",
    "\n",
    "The _height filtration_ is determined by a _height_ function $h : C \\times S^{1} \\to \\mathbb{R}$, assigning to each voxel, direction pair $(c,\\theta)$ the distance from the first seen edge (hyperplane) of $C$ in the direction of $\\theta$ to $c$. Typically we fix the direction $\\theta$ and use $h_{\\theta} : C \\to \\mathbb{R}$ to construct the filtration. If $v$ is a unit vector pointing in the direction of $\\theta$, then $h_{\\theta}(c) = \\langle c ,v \\rangle$. Thus $\\mathcal{F}_{\\theta}(r) = \\{ c | h(c,\\theta) \\leq r \\}$.\n",
    "\n",
    "The _radial filtration_ is determined by a _radial_ function $r : C \\times C \\to \\mathbb{R}$, assigning to each voxel, 'center' pairs $(c,\\rho)$ the distance from $c$ to $\\rho$. Again, this is a function of the 'center' point $\\rho$, which we fix and use $r_{\\rho} : C \\to \\mathbb{R}$. If a voxel $v$ is not in the binarized image, we set $r_{\\rho}(v) = r_{\\infty}$, the maximum value of $r_{\\rho}$. Note that this function also depends on how we measure 'distance', but for this code, we'll use either the $L_1$ or $L_2$ norm of the difference.\n",
    "\n",
    "Sticking closely to the [Garin et. al.], we pick a uniform set of directions and centers for the height filtrations, shown in the figure below.\n",
    "<img src=\"data/directions_and_centers.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "Let's try these out for the binarized digit we've been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.images import RadialFiltration\n",
    "\n",
    "radial_filtration = RadialFiltration(center=np.array([5,25]))\n",
    "digit_rad_filtration = radial_filtration.fit_transform_plot(digit_bin[None,:,:],colorscale='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.images import HeightFiltration\n",
    "\n",
    "height_filtration = HeightFiltration(direction=np.array([1,0]))\n",
    "digit_height_filtration = height_filtration.fit_transform_plot(digit_bin[None,:,:], colorscale='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-scene",
   "metadata": {},
   "source": [
    "The next step is to use either of these filtrations to compute the corresponding persistent homology. Let's use the height filtration as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.homology import CubicalPersistence\n",
    "\n",
    "cubical_persistence = CubicalPersistence(n_jobs=-1)\n",
    "digit_height_persistence = cubical_persistence.fit_transform_plot(digit_height_filtration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-saturday",
   "metadata": {},
   "source": [
    "Now it's time for vectorization. We have several choices of vectorization schemes to use: persistence landscapes, heat kernels, betti curves, etc. We will ultimately use all of these in our pipeline, but for the single digit analysis we'll use the heat kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import HeatKernel\n",
    "\n",
    "heat = HeatKernel(sigma=.15, n_bins=60, n_jobs=-1)\n",
    "digit_heat = heat.fit_transform(digit_height_persistence)\n",
    "\n",
    "# Visualise the heat kernel for H1\n",
    "heat.plot(digit_heat, homology_dimension_idx=1, colorscale='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-pendant",
   "metadata": {},
   "source": [
    "The final step in our pipeline is to take the 'Amplitude' or $L_p$ norm of each vectorization in each homological degree. The Amplitude is a vector $\\vec{a}=(a_0,a_1,\\ldots)$ where each $a_i$ is the $L_p$ norm of the chosen vectorization scheme in homological degree $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-thumb",
   "metadata": {},
   "source": [
    "### Pipeline with the full training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-monster",
   "metadata": {},
   "source": [
    "We combine all of the different filtrations, vectorization schemes, and amplitudes to make one final pipeline. This specific pipeline is taken from [Classifying handwritten digits](https://giotto-ai.github.io/gtda-docs/0.4.0/notebooks/MNIST_classification.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from gtda.diagrams import PersistenceEntropy, Scaler, Amplitude\n",
    "from gtda.images import HeightFiltration, Binarizer\n",
    "\n",
    "\n",
    "direction_list = [[1, 0], [1, 1], [0, 1], [-1, 1], [-1, 0], [-1, -1], [0, -1], [1, -1]]\n",
    "\n",
    "center_list = [\n",
    "    [13, 6],\n",
    "    [6, 13],\n",
    "    [13, 13],\n",
    "    [20, 13],\n",
    "    [13, 20],\n",
    "    [6, 6],\n",
    "    [6, 20],\n",
    "    [20, 6],\n",
    "    [20, 20],\n",
    "]\n",
    "\n",
    "# Creating a list of all filtration transformer, we will be applying\n",
    "filtration_list = (\n",
    "    [\n",
    "        HeightFiltration(direction=np.array(direction), n_jobs=-1)\n",
    "        for direction in direction_list\n",
    "    ]\n",
    "    + [RadialFiltration(center=np.array(center), n_jobs=-1) for center in center_list]\n",
    ")\n",
    "\n",
    "# Creating the diagram generation pipeline\n",
    "diagram_steps = [\n",
    "    [\n",
    "        Binarizer(threshold=0.4),\n",
    "        filtration,\n",
    "        CubicalPersistence(n_jobs=-1),\n",
    "        Scaler(n_jobs=-1),\n",
    "    ]\n",
    "    for filtration in filtration_list\n",
    "]\n",
    "\n",
    "# Listing all metrics we want to use to extract diagram amplitudes\n",
    "metric_list = [\n",
    "    {\"metric\": \"bottleneck\", \"metric_params\": {}},\n",
    "    {\"metric\": \"wasserstein\", \"metric_params\": {\"p\": 1}},\n",
    "    {\"metric\": \"wasserstein\", \"metric_params\": {\"p\": 2}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 1, \"n_layers\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 1, \"n_layers\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 2, \"n_layers\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"landscape\", \"metric_params\": {\"p\": 2, \"n_layers\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"betti\", \"metric_params\": {\"p\": 1, \"n_bins\": 100}},\n",
    "    {\"metric\": \"betti\", \"metric_params\": {\"p\": 2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 1, \"sigma\": 1.6, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 1, \"sigma\": 3.2, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 2, \"sigma\": 1.6, \"n_bins\": 100}},\n",
    "    {\"metric\": \"heat\", \"metric_params\": {\"p\": 2, \"sigma\": 3.2, \"n_bins\": 100}},\n",
    "]\n",
    "\n",
    "#\n",
    "feature_union = make_union(\n",
    "    *[PersistenceEntropy(nan_fill_value=-1)]\n",
    "    + [Amplitude(**metric, n_jobs=-1) for metric in metric_list]\n",
    ")\n",
    "\n",
    "tda_union = make_union(\n",
    "    *[make_pipeline(*diagram_step, feature_union) for diagram_step in diagram_steps],\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-pennsylvania",
   "metadata": {},
   "source": [
    "It can be helpful to visualize the entire Pipeline using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')  \n",
    "\n",
    "tda_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tda = tda_union.fit_transform(X_train)\n",
    "X_train_tda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tda, y_train)\n",
    "\n",
    "X_test_tda = tda_union.transform(X_test)\n",
    "rf.score(X_test_tda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-richardson",
   "metadata": {},
   "source": [
    "How can we improve this classification? We can try to reduce some of the 476 topological features used here. By loooking at the correlation between the features, we can remove highly correlated features and reduce the complexity of the model, also improving efficiency. We could also try other ML algorithms besides Random Forests like SVM, clustering, etc. Even easier, we can increase the training set size to 6,000 or even 60,000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
